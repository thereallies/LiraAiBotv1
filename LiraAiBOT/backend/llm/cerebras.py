"""
Cerebras API –∫–ª–∏–µ–Ω—Ç.
–û—á–µ–Ω—å –±—ã—Å—Ç—Ä—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å LLM (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ Groq).
"""
import asyncio
import logging
import os
from pathlib import Path
from typing import Optional, Any
import aiohttp
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env
load_dotenv()

logger = logging.getLogger("bot.llm")


class CerebrasClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Cerebras API"""

    def __init__(self):
        self.api_key = os.getenv("CEREBRAS_API_KEY", "")
        self.base_url = "https://api.cerebras.ai/v1"

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.default_model = "llama3.1-8b"
        self.max_tokens = 2048
        self.temperature = 0.7

        if self.api_key:
            logger.info(f"‚úÖ Cerebras –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.base_url}")
        else:
            logger.warning("‚ùå CEREBRAS_API_KEY –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")

    async def chat_completion(
        self,
        user_message: str,
        system_prompt: str = "",
        chat_history: Optional[list] = None,
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ chat completion API"""

        model = model or self.default_model
        max_tokens = max_tokens or self.max_tokens
        temperature = temperature or self.temperature

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        if chat_history:
            messages.extend(chat_history)

        messages.append({"role": "user", "content": user_message})

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
        }

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        logger.info(f"üöÄ Cerebras –∑–∞–ø—Ä–æ—Å: {model}, max_tokens={max_tokens}")

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        content = data["choices"][0]["message"]["content"]
                        logger.info(f"‚úÖ Cerebras –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                        return content
                    elif response.status == 403:
                        error_text = await response.text()
                        logger.error(f"‚ùå Cerebras 403 Forbidden: {error_text}")
                        raise Exception(f"Cerebras error 403: {error_text}")
                    else:
                        error_text = await response.text()
                        logger.error(f"‚ùå Cerebras error {response.status}: {error_text}")
                        raise Exception(f"Cerebras error {response.status}: {error_text}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Cerebras: {e}")
            raise


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_cerebras_client: Optional[CerebrasClient] = None


def get_cerebras_client() -> CerebrasClient:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç Cerebras"""
    global _cerebras_client
    if _cerebras_client is None:
        _cerebras_client = CerebrasClient()
    return _cerebras_client
